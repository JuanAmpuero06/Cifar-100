{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Montar Google Drive"
      ],
      "metadata": {
        "id": "jgyuOrg8YhBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet"
      ],
      "metadata": {
        "id": "IGELRatQOpr5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from collections import Counter,deque\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Dz8P4ApPN9Oo"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "# Rutas a tus carpetas de entrenamiento y test en Drive\n",
        "DATASET_TRAIN_PATH = \"/content/drive/MyDrive/simpsons_dataset\"\n",
        "DATASET_TEST_PATH = \"/content/drive/MyDrive/kaggle_simpson_testset\"\n",
        "\n",
        "print(\"Train OK:\", os.path.exists(DATASET_TRAIN_PATH))\n",
        "print(\"Test OK:\", os.path.exists(DATASET_TEST_PATH))"
      ],
      "metadata": {
        "id": "0ahcSFsOFXf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5b5b4a-973d-4fde-a16c-17a2f8001521"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train OK: True\n",
            "Test OK: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Cargar imágenes (entrenamiento y test)"
      ],
      "metadata": {
        "id": "20IDe3REYqaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaño de las imágenes que usaremos\n",
        "IMG_SIZE = 64\n",
        "\n",
        "# Diccionario de personajes (18 más frecuentes)\n",
        "MAP_CHARACTERS = {\n",
        "    0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson',\n",
        "    3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel',\n",
        "    7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson',\n",
        "    11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak',\n",
        "    14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'\n",
        "}\n",
        "\n",
        "# Función para cargar imágenes de entrenamiento\n",
        "def load_train_set(dirname, map_characters, verbose=True):\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for label, character in map_characters.items():\n",
        "        folder_path = os.path.join(dirname, character)\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "        images = [f for f in os.listdir(folder_path) if f.endswith((\"jpg\", \"jpeg\", \"png\"))]\n",
        "        if verbose:\n",
        "            print(f\"Leyendo {len(images)} imágenes de {character}\")\n",
        "        for image_name in images:\n",
        "            image = cv2.imread(os.path.join(folder_path, image_name))\n",
        "            if image is not None:\n",
        "                image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "                X_train.append(image)\n",
        "                y_train.append(label)\n",
        "    return np.array(X_train), np.array(y_train)\n",
        "\n",
        "# Función para cargar imágenes de test\n",
        "def load_test_set(dirname, map_characters, verbose=True):\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    reverse_dict = {v: k for k, v in map_characters.items()}\n",
        "    for filename in glob.glob(dirname + '/*.*'):\n",
        "        char_name = \"_\".join(filename.split('/')[-1].split('_')[:-1])\n",
        "        if char_name in reverse_dict:\n",
        "            image = cv2.imread(filename)\n",
        "            if image is not None:\n",
        "                image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "                X_test.append(image)\n",
        "                y_test.append(reverse_dict[char_name])\n",
        "    if verbose:\n",
        "        print(f\"Leídas {len(X_test)} imágenes de test\")\n",
        "    return np.array(X_test), np.array(y_test)"
      ],
      "metadata": {
        "id": "THK4ap75FXck"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Cargar las imágenes en memoria"
      ],
      "metadata": {
        "id": "CAlaEFvBY19N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos las rutas definidas en el paso 1\n",
        "X, y = load_train_set(DATASET_TRAIN_PATH, MAP_CHARACTERS)\n",
        "X_t, y_t = load_test_set(DATASET_TEST_PATH, MAP_CHARACTERS)\n",
        "\n",
        "print(f\"Total imágenes de entrenamiento: {X.shape}\")\n",
        "print(f\"Total imágenes de test: {X_t.shape}\")"
      ],
      "metadata": {
        "id": "SdrxL23DFXaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae992ce3-a570-4c62-96a6-1871d804ee97"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leyendo 913 imágenes de abraham_grampa_simpson\n",
            "Leyendo 623 imágenes de apu_nahasapeemapetilon\n",
            "Leyendo 1342 imágenes de bart_simpson\n",
            "Leyendo 1193 imágenes de charles_montgomery_burns\n",
            "Leyendo 986 imágenes de chief_wiggum\n",
            "Leyendo 469 imágenes de comic_book_guy\n",
            "Leyendo 457 imágenes de edna_krabappel\n",
            "Leyendo 2246 imágenes de homer_simpson\n",
            "Leyendo 498 imágenes de kent_brockman\n",
            "Leyendo 1206 imágenes de krusty_the_clown\n",
            "Leyendo 1354 imágenes de lisa_simpson\n",
            "Leyendo 1291 imágenes de marge_simpson\n",
            "Leyendo 1079 imágenes de milhouse_van_houten\n",
            "Leyendo 1452 imágenes de moe_szyslak\n",
            "Leyendo 1454 imágenes de ned_flanders\n",
            "Leyendo 358 imágenes de nelson_muntz\n",
            "Leyendo 1194 imágenes de principal_skinner\n",
            "Leyendo 877 imágenes de sideshow_bob\n",
            "Leídas 890 imágenes de test\n",
            "Total imágenes de entrenamiento: (18992, 64, 64, 3)\n",
            "Total imágenes de test: (890, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Separar train y validation (80/20) + normalizar"
      ],
      "metadata": {
        "id": "lg4eL1QrmVF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar imágenes a rango [0,1]\n",
        "X = X.astype('float32') / 255.0\n",
        "X_t = X_t.astype('float32') / 255.0\n",
        "\n",
        "# División con estratificación para mantener balance de clases\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Imágenes para entrenar: {X_train.shape}, Para Validar: {X_val.shape}\")"
      ],
      "metadata": {
        "id": "jfhx523xOue9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4045a137-3cfe-4a2c-df71-348e6be2221a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes para entrenar: (15193, 64, 64, 3), Para Validar: (3799, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Definir tu modelo CNN básico"
      ],
      "metadata": {
        "id": "hyHAlr39mm4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(MAP_CHARACTERS)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(64, 64, 3)),\n",
        "\n",
        "    # Convolución 1\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolución 2\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolución 3\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Capa completamente conectada\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    # Capa de salida\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "0AvxbdbGmbX5",
        "outputId": "78a0c179-c9be-4773-9d5c-6d4a41da5c61"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,097,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m4,626\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,626</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,196,178\u001b[0m (8.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,196,178</span> (8.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,195,730\u001b[0m (8.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,195,730</span> (8.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Entrenamiento del modelo con métricas y callbacks"
      ],
      "metadata": {
        "id": "e154f3ORnEmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks para entrenamiento robusto\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=7,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "i7VaOp6aOucX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Entrenar el modelo"
      ],
      "metadata": {
        "id": "Ve7IvhEO7Fy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, checkpoint, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGTsiST560id",
        "outputId": "ea6fefb3-91cf-4f77-fce5-533b0792c5ab"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2215 - loss: 2.9090\n",
            "Epoch 1: val_loss improved from inf to 3.92178, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - accuracy: 0.2218 - loss: 2.9069 - val_accuracy: 0.2037 - val_loss: 3.9218 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m235/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4647 - loss: 1.7689\n",
            "Epoch 2: val_loss improved from 3.92178 to 1.61422, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4650 - loss: 1.7677 - val_accuracy: 0.5080 - val_loss: 1.6142 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m234/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5875 - loss: 1.3447\n",
            "Epoch 3: val_loss improved from 1.61422 to 1.10191, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5877 - loss: 1.3436 - val_accuracy: 0.6565 - val_loss: 1.1019 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6814 - loss: 0.9975\n",
            "Epoch 4: val_loss improved from 1.10191 to 0.86669, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.6815 - loss: 0.9976 - val_accuracy: 0.7470 - val_loss: 0.8667 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7419 - loss: 0.8075\n",
            "Epoch 5: val_loss did not improve from 0.86669\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7420 - loss: 0.8074 - val_accuracy: 0.7115 - val_loss: 1.0422 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7961 - loss: 0.6385\n",
            "Epoch 6: val_loss improved from 0.86669 to 0.68306, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7961 - loss: 0.6383 - val_accuracy: 0.8068 - val_loss: 0.6831 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8362 - loss: 0.5146\n",
            "Epoch 7: val_loss improved from 0.68306 to 0.60858, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8362 - loss: 0.5146 - val_accuracy: 0.8460 - val_loss: 0.6086 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8709 - loss: 0.3926\n",
            "Epoch 8: val_loss improved from 0.60858 to 0.59135, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.8709 - loss: 0.3927 - val_accuracy: 0.8439 - val_loss: 0.5913 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8947 - loss: 0.3184\n",
            "Epoch 9: val_loss improved from 0.59135 to 0.57696, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8946 - loss: 0.3188 - val_accuracy: 0.8576 - val_loss: 0.5770 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9134 - loss: 0.2656\n",
            "Epoch 10: val_loss improved from 0.57696 to 0.55727, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9134 - loss: 0.2657 - val_accuracy: 0.8710 - val_loss: 0.5573 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m233/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.2334\n",
            "Epoch 11: val_loss did not improve from 0.55727\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9228 - loss: 0.2335 - val_accuracy: 0.8460 - val_loss: 0.5968 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m234/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9316 - loss: 0.2092\n",
            "Epoch 12: val_loss did not improve from 0.55727\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9316 - loss: 0.2093 - val_accuracy: 0.8644 - val_loss: 0.5719 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m235/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9387 - loss: 0.1842\n",
            "Epoch 13: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9387 - loss: 0.1843 - val_accuracy: 0.8665 - val_loss: 0.5728 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.1336\n",
            "Epoch 14: val_loss improved from 0.55727 to 0.48779, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9565 - loss: 0.1336 - val_accuracy: 0.8984 - val_loss: 0.4878 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m234/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9663 - loss: 0.1054\n",
            "Epoch 15: val_loss did not improve from 0.48779\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9663 - loss: 0.1053 - val_accuracy: 0.8968 - val_loss: 0.5115 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9721 - loss: 0.0809\n",
            "Epoch 16: val_loss did not improve from 0.48779\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9721 - loss: 0.0809 - val_accuracy: 0.8994 - val_loss: 0.5085 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9780 - loss: 0.0664\n",
            "Epoch 17: val_loss did not improve from 0.48779\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9780 - loss: 0.0664 - val_accuracy: 0.8963 - val_loss: 0.5574 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.0579\n",
            "Epoch 18: val_loss did not improve from 0.48779\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9826 - loss: 0.0579 - val_accuracy: 0.9068 - val_loss: 0.4949 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0504\n",
            "Epoch 19: val_loss did not improve from 0.48779\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0505 - val_accuracy: 0.9118 - val_loss: 0.4939 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0423\n",
            "Epoch 20: val_loss improved from 0.48779 to 0.48283, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0423 - val_accuracy: 0.9110 - val_loss: 0.4828 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0445\n",
            "Epoch 21: val_loss did not improve from 0.48283\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9856 - loss: 0.0445 - val_accuracy: 0.9152 - val_loss: 0.4849 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m233/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9859 - loss: 0.0458\n",
            "Epoch 22: val_loss did not improve from 0.48283\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9860 - loss: 0.0456 - val_accuracy: 0.9089 - val_loss: 0.5009 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m235/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0341\n",
            "Epoch 23: val_loss did not improve from 0.48283\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0341 - val_accuracy: 0.9137 - val_loss: 0.5188 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m234/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9892 - loss: 0.0343\n",
            "Epoch 24: val_loss did not improve from 0.48283\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0342 - val_accuracy: 0.9147 - val_loss: 0.5100 - learning_rate: 1.2500e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m236/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0264\n",
            "Epoch 25: val_loss did not improve from 0.48283\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0264 - val_accuracy: 0.9168 - val_loss: 0.5127 - learning_rate: 1.2500e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m233/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.0294\n",
            "Epoch 26: val_loss did not improve from 0.48283\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0294 - val_accuracy: 0.9160 - val_loss: 0.5154 - learning_rate: 1.2500e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m235/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0277\n",
            "Epoch 27: val_loss did not improve from 0.48283\n",
            "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0277 - val_accuracy: 0.9145 - val_loss: 0.5227 - learning_rate: 6.2500e-05\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graficar métricas de entrenamiento"
      ],
      "metadata": {
        "id": "uZt1qiQO7pmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy durante el entrenamiento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss durante el entrenamiento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1JLHRFPOuZV"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Evaluar el modelo entrenado(Cargar el mejor modelo)"
      ],
      "metadata": {
        "id": "x2yZHPZx8KTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga del mejor modelo guardado por ModelCheckpoint\n",
        "model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "8xjubPcbFXXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e4b80b-1b58-42a6-af36-6ae5f172bf6e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Realizar predicciones"
      ],
      "metadata": {
        "id": "v0GNRcZ89EDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = model.predict(X_t)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWBH_hzh8Pod",
        "outputId": "7d2f178d-e220-4626-995a-2005faf0a784"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generar métricas de evaluación"
      ],
      "metadata": {
        "id": "aT13nKSj9Q-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte por clase\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_t, y_pred, target_names=list(MAP_CHARACTERS.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o13pyjcM9QIr",
        "outputId": "3b782b6f-b555-4832-f5ab-dbef1a058cce"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "  abraham_grampa_simpson       1.00      0.90      0.95        48\n",
            "  apu_nahasapeemapetilon       0.96      0.98      0.97        50\n",
            "            bart_simpson       0.94      0.98      0.96        50\n",
            "charles_montgomery_burns       0.90      0.98      0.94        48\n",
            "            chief_wiggum       1.00      1.00      1.00        50\n",
            "          comic_book_guy       1.00      0.96      0.98        49\n",
            "          edna_krabappel       1.00      0.98      0.99        50\n",
            "           homer_simpson       0.91      0.98      0.94        50\n",
            "           kent_brockman       1.00      0.96      0.98        50\n",
            "        krusty_the_clown       1.00      1.00      1.00        50\n",
            "            lisa_simpson       0.98      0.94      0.96        50\n",
            "           marge_simpson       1.00      1.00      1.00        50\n",
            "     milhouse_van_houten       1.00      1.00      1.00        49\n",
            "             moe_szyslak       0.98      1.00      0.99        50\n",
            "            ned_flanders       1.00      1.00      1.00        49\n",
            "            nelson_muntz       1.00      1.00      1.00        50\n",
            "       principal_skinner       0.98      1.00      0.99        50\n",
            "            sideshow_bob       1.00      0.98      0.99        47\n",
            "\n",
            "                accuracy                           0.98       890\n",
            "               macro avg       0.98      0.98      0.98       890\n",
            "            weighted avg       0.98      0.98      0.98       890\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Matriz de confusión"
      ],
      "metadata": {
        "id": "CjA8AoH69q9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_t, y_pred)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=MAP_CHARACTERS.values(), yticklabels=MAP_CHARACTERS.values(), cmap='Blues')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor real')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P5GmRorI8PlC"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Predicción frame a frame desde video con Gradio"
      ],
      "metadata": {
        "id": "8rEFbEuf-OiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SS6houC7-hPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar modelo\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "# Tamaño esperado por la red\n",
        "IMG_SIZE = 64\n",
        "\n",
        "# Lista de nombres de clase\n",
        "class_names = list(MAP_CHARACTERS.values())\n",
        "\n",
        "# Función de predicción frame a frame\n",
        "def predict_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_preds = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocesar el frame\n",
        "        frame_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
        "        frame_norm = frame_resized.astype('float32') / 255.0\n",
        "        frame_input = np.expand_dims(frame_norm, axis=0)\n",
        "\n",
        "        # Predicción\n",
        "        prediction = model.predict(frame_input, verbose=0)\n",
        "        pred_class = np.argmax(prediction)\n",
        "        frame_preds.append(class_names[pred_class])\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Analizar predicciones\n",
        "    if not frame_preds:\n",
        "        return \"No se pudo procesar el video.\"\n",
        "\n",
        "    top = Counter(frame_preds).items()\n",
        "    result = \"\\n\".join([f\"{char}: {count} frames\" for char, count in top])\n",
        "    return f\"Personajes detectados:\\n{result}\"\n",
        "\n",
        "# Interfaz Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=predict_video,\n",
        "    inputs=gr.Video(label=\"Sube un video de Los Simpsons\"),\n",
        "    outputs=gr.Textbox(label=\"Resultado\"),\n",
        "    title=\"Detector de personajes de Los Simpsons\",\n",
        "    description=\"Este modelo analiza frame por frame un video y detecta los personajes de los simpsons.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "GxLwx4iS8PgM",
        "outputId": "9c8695ea-c4ff-42f6-f43e-020f7b76c067"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c12445fdfbdecc04c4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c12445fdfbdecc04c4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    }
  ]
}